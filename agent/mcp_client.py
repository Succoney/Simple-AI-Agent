import asyncio
from mcp import ClientSession,StdioServerParameters
from mcp.client.stdio import stdio_client
from contextlib import AsyncExitStack
from openai import OpenAI
from dotenv import load_dotenv
import os
from typing import Optional
import json


class MCPClient:
    def __init__(self):
        load_dotenv("../config/config.env")
        self.exit_stack = AsyncExitStack()
        self.model = os.getenv("model")
        self.api_key = os.getenv("api_key")
        self.base_url = os.getenv("base_url")
        self.client = OpenAI(api_key = self.api_key,base_url = self.base_url)
        self.session : List[ClientSession] = []
        self.toolid = dict()


    async def web_search(self, query : str) -> list[dict]:
        pass


    async def process_query(self, messages : list[dict]) -> list[dict]:
        """
        ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†æŸ¥è¯¢å¹¶è°ƒç”¨å¯ç”¨çš„ MCP å·¥å…· (Function Calling)
        """

        available_tools = []
        query = messages[0]["content"]

        for index, session in enumerate(self.session):
            responce = await session.list_tools()

            server_available_tools = [{
                "type" : "function",
                "function" : {
                    "name" : tool.name,
                    "description" : tool.description,
                    "input_schema" : tool.inputSchema
                }
            } for tool in responce.tools]

            for tool in responce.tools:
                self.toolid[tool.name] = index

            available_tools += server_available_tools

        try:
            if query == "file upload":
                result = await self.session[self.toolid["file_upload"]].call_tool("file_upload")
                query = input("File upload successfully! Query about the file: ").strip()
                messages+=[{
                        "role": "user",
                        "content": result.content[0].text,
                    },{
                        "role": "user",
                        "content": query
                    }]
                

                response = self.client.chat.completions.create(
                    model = self.model,
                    messages = messages,
                )

                return response.choices[0].message.content

            elif query == "image upload":
                result = await self.session[self.toolid["image_upload"]].call_tool("image_upload")
                query = input("File upload successfully! Query about the file: ").strip()
                messages+=[{
                        "role": "user",
                        "content": result.content[0].text,
                    },{
                        "role": "user",
                        "content": query
                    }]
                

                response = self.client.chat.completions.create(
                    model = self.model,
                    messages = messages,
                )

                return response.choices[0].message.content
                
            else:

                response = self.client.chat.completions.create(
                        model = self.model,
                        messages = messages,
                        tools = available_tools
                    )


                messages = [messages[-1]]

                content = response.choices[0]

                if content.finish_reason == "tool_calls":
                    # å¦‚æœæ˜¯éœ€è¦ä½¿ç”¨å·¥å…·å°±è§£æå·¥å…·
                    tool_call = content.message.tool_calls[0]
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)

                    print(f"\n[Calling tool {tool_name} with args {tool_args}]")

                    # æ‰§è¡Œå·¥å…·
                    result = await self.session[self.toolid[tool_name]].call_tool(tool_name,tool_args)

                    messages.append(content.message.model_dump())

                    messages.append({
                        "role" : "tool",
                        "content" : result.content[0].text,
                        "tool_call_id" : tool_call.id,
                    })

                    # å°†å·¥å…·è°ƒç”¨ç»“æœæ”¾åˆ°messagesä¸­

                    return messages
                else:

                    messages.append({
                        "role" : "assistant",
                        "content" : response.choices[0].message.content,
                    })
                    
                    return messages
        except Exception as e:
            return f"é”™è¯¯ä¿¡æ¯ï¼š{str(e)}"


    async def connect_to_mock_server(self, server_script_path: str):
        "æ¨¡æ‹Ÿ mcp æœåŠ¡å™¨çš„è¿æ¥"
        print(" mcp å®¢æˆ·ç«¯å·²å®Œæˆåˆå§‹åŒ–, å‡†å¤‡è¿æ¥æœåŠ¡å™¨")
        if_python = server_script_path.endswith(".py")
        if_js = server_script_path.endswith(".js")

        if not if_python and not if_js:
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ–è€… .js æ–‡ä»¶")

        command = "python" if if_python else "node"

        # è®¾ç½®æ ‡å‡†è¾“å…¥è¾“å‡ºé€šä¿¡çš„å‚æ•°
        server_params = StdioServerParameters(
            command = command,
            args = [server_script_path],
            env = None
        )

        # å¯åŠ¨ MCP å¹¶å»ºç«‹é€šä¿¡
        # exit_stackæ˜¯contextlibåˆ›å»ºçš„å¯¹è±¡,ç”¨äºç®¡ç†å¤šä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚
        # enter_async_context è¿›å…¥ä¸€ä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¹¶è¿”å›è¯¥ç®¡ç†å™¨
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params)) # åˆ›å»ºä¸€ä¸ªæ ‡å‡†ioé€šä¿¡
        self.stdio, self.write = stdio_transport
        session = await self.exit_stack.enter_async_context(ClientSession(self.stdio,self.write)) # åˆ›å»ºä¸€ä¸ªå®¢æˆ·ç«¯ä¼šè¯

        await session.initialize() # ä¼šè¯åˆå§‹åŒ–

        # åˆ—å‡º MCP æœåŠ¡å™¨ä¸Šçš„å·¥å…·
        response = await session.list_tools() # åˆ—å‡ºæœåŠ¡å™¨çš„å·¥å…·
        tools = response.tools
        print("\nä»¥è¿æ¥åˆ°æœåŠ¡å™¨,æ”¯æŒä¸€ä¸‹å·¥å…·:",[tool for tool in tools])
        self.session.append(session)



    async def loop_chat(self) -> str:
        "è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"
        print("\n MCP å®¢æˆ·ç«¯å·²å¯åŠ¨!")
        try:
            while(True):
                query = input("Query: ").strip()

                if query == "":
                    print("You don't input any query, please give me some queryã€‚ğŸ¥ºğŸ¥ºğŸ¥º")
                    continue

                if "quit()" in query.lower():
                    break
                else:
                    messages = [{
                        "role" : "user",
                        "content" : query,
                    }]
                    response = await self.process_query(messages)
                    print(response)
        except Exception as e:
            return str(e)

    async def cleanup(self):
        await self.exit_stack.aclose()

async def main():
    
    if len(sys.argv) < 2:
        print("Usage: python mcp_client.py <path_to_server_script>")
        sys.exit(1)
    client = MCPClient()
    try:
        for i in range(1,len(sys.argv)):
            await client.connect_to_mock_server(sys.argv[i])
        await client.loop_chat()
    finally:
        await client.cleanup()

if __name__ == "__main__":
    import sys
    asyncio.run(main())